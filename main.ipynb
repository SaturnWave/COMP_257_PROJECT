{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T18:07:26.569909Z",
     "start_time": "2024-11-05T18:07:23.381405Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "# Load the UMIST dataset from .mat file\n",
    "mat_file_path = 'umist_cropped.mat'\n",
    "mat_data = scipy.io.loadmat(mat_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1912adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract facedat and dirnames\n",
    "facedat = mat_data['facedat'][0]\n",
    "dirnames = mat_data['dirnames'][0]\n",
    "\n",
    "# Create lists to store processed images and labels\n",
    "images = []\n",
    "labels = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f85e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each person's data\n",
    "# Alternative with padding (if you need numpy array output)\n",
    "max_width = max(max(img.shape[1] for img in person_data if len(img) > 0) for person_data in facedat)\n",
    "padded_images = []\n",
    "\n",
    "for person_data in facedat:\n",
    "    for img in person_data:\n",
    "        if isinstance(img, np.ndarray) and img.size > 0:\n",
    "            padded = np.zeros((92, max_width))\n",
    "            padded[:, :img.shape[1]] = img\n",
    "            padded_images.append(padded)\n",
    "\n",
    "images = np.array(padded_images)\n",
    "labels = np.repeat(np.arange(len(facedat)), [len(person_data) for person_data in facedat if len(person_data) > 0])\n",
    "##Outher loop iterates thorugh each person's data (Subject),\n",
    "### Inner Loop iterates thorugh each image of that person \n",
    "###Structure: facedat is nested array where facedat[i] contains all images for person i\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d591913",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Converting labels to numpy arrays\n",
    "labels = np.array(labels)\n",
    "###labels is a list of integers where each integer represents the person in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a1ed06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First split: temporary train (85%) and test (15%)\n",
    "indices = np.arange(len(images))\n",
    "idx_temp_train, idx_test, y_temp_train, y_test = train_test_split(\n",
    "    indices, \n",
    "    labels,\n",
    "    test_size=0.15,  ##Test size is 15% of the data (85% is for training)\n",
    "    stratify=labels, ##Stratification is used to ensure that the train and test sets have the same distribution of labels\n",
    "    random_state=42 ##Random state is used to ensure reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c51fa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second split: final train (70%) and validation (15%)\n",
    "idx_train, idx_val, y_train, y_val = train_test_split(\n",
    "    idx_temp_train,\n",
    "    y_temp_train,\n",
    "    test_size=0.176,\n",
    "    stratify=y_temp_train,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "##In the second train-test split, the temporary train set is split into the final train and validation sets\n",
    "##The final train set is 70% of the data and the validation set is 15% of the data\n",
    "##Remanining 15% of the data is used for testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dcac36cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [images[i] for i in idx_train]\n",
    "X_val = [images[i] for i in idx_val]\n",
    "X_test = [images[i] for i in idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99da0fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Split Sizes:\n",
      "Training set: 1568 images (70.0%)\n",
      "Validation set: 336 images (15.0%)\n",
      "Test set: 336 images (15.0%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDataset Split Sizes:\")\n",
    "print(f\"Training set: {len(X_train)} images ({len(X_train)/len(images)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(X_val)} images ({len(X_val)/len(images)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(X_test)} images ({len(X_test)/len(images)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2aa453e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_split(images, labels, prefix):\n",
    "    # Find the maximum width to pad all images to the same size\n",
    "    max_width = max(img.shape[1] for img in images)\n",
    "    height = images[0].shape[0]  # All images have same height (92)\n",
    "    \n",
    "    # Create padded array\n",
    "    padded_images = np.zeros((len(images), height, max_width))\n",
    "    \n",
    "    # Fill the padded array\n",
    "    for i, img in enumerate(images):\n",
    "        w = img.shape[1]\n",
    "        padded_images[i, :, :w] = img\n",
    "    \n",
    "    # Save as compressed npz file\n",
    "    np.savez_compressed(\n",
    "        f'umist_split_{prefix}.npz',\n",
    "        images=padded_images,\n",
    "        labels=labels,\n",
    "        original_widths=[img.shape[1] for img in images]  # Save original widths for later\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "014301e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved splits successfully!\n",
      "Files created:\n",
      "- umist_split_train.npz\n",
      "- umist_split_val.npz\n",
      "- umist_split_test.npz\n",
      "\n",
      "Verifying train split:\n",
      "Images shape: (1568, 92, 48)\n",
      "Labels shape: (1568,)\n",
      "Number of original widths: 1568\n",
      "\n",
      "Verifying val split:\n",
      "Images shape: (336, 92, 48)\n",
      "Labels shape: (336,)\n",
      "Number of original widths: 336\n",
      "\n",
      "Verifying test split:\n",
      "Images shape: (336, 92, 48)\n",
      "Labels shape: (336,)\n",
      "Number of original widths: 336\n"
     ]
    }
   ],
   "source": [
    "# Save all splits\n",
    "save_split(X_train, y_train, 'train')\n",
    "save_split(X_val, y_val, 'val')\n",
    "save_split(X_test, y_test, 'test')\n",
    "\n",
    "print(\"\\nSaved splits successfully!\")\n",
    "print(\"Files created:\")\n",
    "print(\"- umist_split_train.npz\")\n",
    "print(\"- umist_split_val.npz\")\n",
    "print(\"- umist_split_test.npz\")\n",
    "\n",
    "# Function to load and verify the saved data\n",
    "def load_and_verify_split(prefix):\n",
    "    data = np.load(f'umist_split_{prefix}.npz')\n",
    "    print(f\"\\nVerifying {prefix} split:\")\n",
    "    print(f\"Images shape: {data['images'].shape}\")\n",
    "    print(f\"Labels shape: {data['labels'].shape}\")\n",
    "    print(f\"Number of original widths: {len(data['original_widths'])}\")\n",
    "    return data\n",
    "\n",
    "# Verify saved data\n",
    "train_data = load_and_verify_split('train')\n",
    "val_data = load_and_verify_split('val')\n",
    "test_data = load_and_verify_split('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "026e2314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing Summary:\n",
      "Original shape: (92, 48)\n",
      "After flattening: (2240, 4416)\n",
      "After PCA: (2240, 139)\n",
      "Variance explained ratio: 0.950\n",
      "Number of components kept: 139\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import cv2\n",
    "\n",
    "def preprocess_umist_data(images, labels):\n",
    "    \"\"\"\n",
    "    Comprehensive preprocessing pipeline for UMIST dataset\n",
    "    \"\"\"\n",
    "    # 1. Image Normalization\n",
    "    # Convert to float32 for better numerical precision\n",
    "    normalized_images = np.array([img.astype(np.float32) for img in images])\n",
    "    \n",
    "    # Min-max normalization to [0,1] range\n",
    "    normalized_images = np.array([\n",
    "        (img - np.min(img)) / (np.max(img) - np.min(img))\n",
    "        for img in normalized_images\n",
    "    ])\n",
    "    \n",
    "    # 2. Histogram Equalization for better contrast\n",
    "    equalized_images = np.array([\n",
    "        cv2.equalizeHist((img * 255).astype(np.uint8)).astype(np.float32) / 255\n",
    "        for img in normalized_images\n",
    "    ])\n",
    "    \n",
    "    # 3. Standardization (z-score normalization)\n",
    "    # Reshape to 2D array for StandardScaler\n",
    "    n_samples = len(equalized_images)\n",
    "    n_features = equalized_images[0].size\n",
    "    X = equalized_images.reshape(n_samples, -1)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # 4. PCA for dimensionality reduction\n",
    "    # Keep 95% of variance\n",
    "    pca = PCA(n_components=0.95, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(\"\\nPreprocessing Summary:\")\n",
    "    print(f\"Original shape: {images[0].shape}\")\n",
    "    print(f\"After flattening: {X.shape}\")\n",
    "    print(f\"After PCA: {X_pca.shape}\")\n",
    "    print(f\"Variance explained ratio: {np.sum(pca.explained_variance_ratio_):.3f}\")\n",
    "    print(f\"Number of components kept: {pca.n_components_}\")\n",
    "    \n",
    "    return X_pca, pca, scaler\n",
    "\n",
    "# Apply preprocessing\n",
    "X_processed, pca, scaler = preprocess_umist_data(images, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
